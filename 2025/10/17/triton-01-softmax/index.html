<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>triton-01-softmax - Coder Zhu</title>

  
    <meta name="description" content="介绍Triton是OpenAI开发的一种编程语言，帮助没有CUDA经验的开发者快速编写高性能GPU算子，实现加速。 作为上手的第一次尝试，本文以Softmax为例，体验一下triton的编写流程。Softmax是深度学习中一个基础算子，可用来将原始分数（Logits）转化为概率分布，常用于分类网络。 一维场景：$X,Y \in \mathbb{R}^{N}$  \text{Softmax}(x_i">
<meta property="og:type" content="article">
<meta property="og:title" content="triton-01-softmax">
<meta property="og:url" content="https://vincentzhu007.github.io/2025/10/17/triton-01-softmax/index.html">
<meta property="og:site_name" content="Coder Zhu">
<meta property="og:description" content="介绍Triton是OpenAI开发的一种编程语言，帮助没有CUDA经验的开发者快速编写高性能GPU算子，实现加速。 作为上手的第一次尝试，本文以Softmax为例，体验一下triton的编写流程。Softmax是深度学习中一个基础算子，可用来将原始分数（Logits）转化为概率分布，常用于分类网络。 一维场景：$X,Y \in \mathbb{R}^{N}$  \text{Softmax}(x_i">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vincentzhu007.github.io/2025/10/17/triton-01-softmax/triton-softmax.png">
<meta property="article:published_time" content="2025-10-17T16:24:12.000Z">
<meta property="article:modified_time" content="2025-10-17T16:29:50.990Z">
<meta property="article:author" content="Vincent Zhu">
<meta property="article:tag" content="triton">
<meta property="article:tag" content="softmax">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vincentzhu007.github.io/2025/10/17/triton-01-softmax/triton-softmax.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
    
      <link href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.6.0/style.css" rel="stylesheet">
    
      <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC&display=swap" rel="stylesheet">
    
  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">Coder Zhu</div><div class="sub cap">Veni, Vidi, Vici</div></a></div>

<nav class="menu dis-select"><a class="nav-item active" href="/">博客</a><a class="nav-item" href="/wiki">项目</a><a class="nav-item" href="/about/">关于</a></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">triton-01-softmax</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Softmax%E5%AE%9E%E7%8E%B0"><span class="toc-text">Softmax实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9Asoftmax%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E6%8A%80%E5%B7%A7"><span class="toc-text">补充：softmax数值计算技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-text">参考</span></a></li></ol></div></div></widget>




</div>


    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/triton/">triton</a></div><div id="post-meta">发布于&nbsp;<time datetime="2025-10-17T16:24:12.000Z">2025-10-18</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>triton-01-softmax</span></h1>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>Triton是OpenAI开发的一种编程语言，帮助没有CUDA经验的开发者快速编写高性能GPU算子，实现加速。</p>
<p>作为上手的第一次尝试，本文以Softmax为例，体验一下triton的编写流程。Softmax是深度学习中一个基础算子，可用来将原始分数（Logits）转化为概率分布，常用于分类网络。</p>
<p>一维场景：$X,Y \in \mathbb{R}^{N}$</p>
<script type="math/tex; mode=display">
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=1}^{N}{e^{x_j}}}</script><p>二维场景：$X,Y \in \mathbb{R}^{M \times N}$</p>
<script type="math/tex; mode=display">
\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=0}^{N}{e^{x_{i,j}}}}, i=1,...M</script><p>这里，$x_i$是一个长度为$N$的向量。</p>
<p>本文使用triton来实现一个二维softmax算子，并与torch softmax对比精度，确认实现的正确性。</p>
<h3 id="Softmax实现"><a href="#Softmax实现" class="headerlink" title="Softmax实现"></a>Softmax实现</h3><blockquote>
<p><strong>说明：</strong><br>实验环境：AutoDL 容器 RTX 2080 Ti(11GB)<br>PyTorch  2.5.1<br>Python  3.12(ubuntu22.04)<br>CUDA  12.4</p>
</blockquote>
<p>安装triton：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install triton</span><br></pre></td></tr></table></figure>
<p>triton softmax实现（参考openai triton官网实现）：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2025/10/17/triton-01-softmax/triton-softmax.png" alt="softmax计算流程图"></p>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> triton</span><br><span class="line"><span class="keyword">import</span> triton.language <span class="keyword">as</span> tl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对二维Tensor计算Softmax</span></span><br><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">triton_softmax</span>(<span class="params">Y, stride_ym, stride_yn, X, stride_xm, stride_xn, M, N</span>):</span><br><span class="line">    <span class="comment"># 取某一行的索引</span></span><br><span class="line">    m = tl.program_id(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取某一列的索引</span></span><br><span class="line">    BLOCK_SIZE : tl.constexpr = <span class="number">1024</span></span><br><span class="line">    n = tl.arange(<span class="number">0</span>, BLOCK_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># X取某一行的向量</span></span><br><span class="line">    X = X + m * stride_xm + n * stride_xn</span><br><span class="line">    <span class="comment"># 加载行向量，如果超过N，就用inf填充</span></span><br><span class="line">    x = tl.load(X, mask=n &lt; N, other=-<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算softmax</span></span><br><span class="line">    <span class="comment"># 首先，x - max(x)；减去最大值，提高数值稳定性</span></span><br><span class="line">    z =  x - tl.<span class="built_in">max</span>(x, axis=<span class="number">0</span>)</span><br><span class="line">    num = tl.exp(z)</span><br><span class="line">    denom = tl.<span class="built_in">sum</span>(num, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    y = num / denom <span class="comment"># 分子/分母</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写回到Y</span></span><br><span class="line">    Y = Y + m * stride_ym + n * stride_yn</span><br><span class="line">    tl.store(Y, y, mask= n &lt; N)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用Triton Softmax算子，与torch实现对比精度。</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line">X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, size=(<span class="number">583</span>, <span class="number">931</span>), device=<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">Y = torch.empty_like(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置SPMD的网格</span></span><br><span class="line">grid = (X.shape[<span class="number">0</span>], )</span><br><span class="line">triton_softmax[grid](Y, Y.stride(<span class="number">0</span>), Y.stride(<span class="number">1</span>),</span><br><span class="line">                     X, X.stride(<span class="number">0</span>), X.stride(<span class="number">1</span>),</span><br><span class="line">                     X.shape[<span class="number">0</span>], X.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Y_triton = <span class="subst">&#123;Y&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Y_torch = torch.nn.Softmax(dim=<span class="number">1</span>)(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Y_torch = <span class="subst">&#123;Y_torch&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ok = torch.allclose(Y, Y_torch)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;equal ? <span class="subst">&#123;ok&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Y_triton = tensor([[7.4673e-04, 5.3404e-03, 5.1782e-04,  ..., 3.1986e-03, 2.1141e-04,</span><br><span class="line">         5.1145e-04],</span><br><span class="line">        [1.9864e-03, 3.3511e-05, 2.1382e-03,  ..., 7.2760e-04, 4.7654e-04,</span><br><span class="line">         3.8883e-03],</span><br><span class="line">        [1.8407e-03, 2.7075e-04, 7.4302e-04,  ..., 8.6954e-04, 2.7257e-03,</span><br><span class="line">         2.6177e-03],</span><br><span class="line">        ...,</span><br><span class="line">        [2.9115e-03, 1.3667e-04, 1.6691e-03,  ..., 1.6625e-03, 2.2443e-03,</span><br><span class="line">         2.6430e-03],</span><br><span class="line">        [5.0886e-04, 2.1393e-04, 4.7878e-04,  ..., 1.7784e-03, 1.0859e-04,</span><br><span class="line">         5.6565e-04],</span><br><span class="line">        [1.3451e-04, 2.1544e-03, 1.6709e-03,  ..., 4.5203e-04, 9.8369e-05,</span><br><span class="line">         7.7892e-04]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">Y_torch = tensor([[7.4673e-04, 5.3404e-03, 5.1782e-04,  ..., 3.1986e-03, 2.1140e-04,</span><br><span class="line">         5.1145e-04],</span><br><span class="line">        [1.9864e-03, 3.3511e-05, 2.1382e-03,  ..., 7.2760e-04, 4.7654e-04,</span><br><span class="line">         3.8883e-03],</span><br><span class="line">        [1.8407e-03, 2.7075e-04, 7.4302e-04,  ..., 8.6954e-04, 2.7257e-03,</span><br><span class="line">         2.6177e-03],</span><br><span class="line">        ...,</span><br><span class="line">        [2.9115e-03, 1.3667e-04, 1.6691e-03,  ..., 1.6625e-03, 2.2443e-03,</span><br><span class="line">         2.6430e-03],</span><br><span class="line">        [5.0886e-04, 2.1393e-04, 4.7879e-04,  ..., 1.7784e-03, 1.0859e-04,</span><br><span class="line">         5.6565e-04],</span><br><span class="line">        [1.3451e-04, 2.1544e-03, 1.6709e-03,  ..., 4.5203e-04, 9.8369e-05,</span><br><span class="line">         7.7892e-04]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">equal ? True</span><br></pre></td></tr></table></figure>
<p>验证了triton和torch softmax输出结果一致。</p>
<h3 id="补充：softmax数值计算技巧"><a href="#补充：softmax数值计算技巧" class="headerlink" title="补充：softmax数值计算技巧"></a>补充：softmax数值计算技巧</h3><p>当输入x值的范围很大时，exp(x)的数值也很大，会上溢为nan；当所有的x值都接近-inf时，sum(exp(x))就接近0，作为分母容易导致除法不稳定。</p>
<p>这里可以通过数学上的变换小技巧，通过减去x的最大值，可使exp()的值小于1，另外由于$x<em>{max} - x</em>{max} = 0$，由于0的存在，exp(0)=1，不会使得所有分母都接近0，推导如下：</p>
<script type="math/tex; mode=display">
\begin{align*}
\text{Softmax}(x_i) 
&= 
\frac{e^{x_i} / e^{x_{max}}}{\sum_{j=1}^{N}{e^{x_j} / e^{x_{max} }}} \\
&=
\frac{e^{x_i - x_{max}}}{\sum_{j=1}^{N}{e^{x_j - x_{max}}}}
\end{align*}</script><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a target="_blank" rel="noopener" href="https://openai.com/index/triton/"><strong>Introducing Triton: Open-source GPU programming for neural networks</strong></a></p>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2025/04/02/self-llm-001-extract-dialogue/">甄嬛Chat复现-Part01-从剧本文件提取对话</a></div></section></div>








      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.18.5';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"codeblock":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
